{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sparknotesqa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpOpSj6klu0Apq5KXOZ7nR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymann/sparknotesqa/blob/master/Sparknotesqa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAMuYsPG6nms",
        "colab_type": "text"
      },
      "source": [
        "## Running the Sparknotes models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqpdNdJj6uLk",
        "colab_type": "text"
      },
      "source": [
        "### 1. Paragraph extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2PuquUi0t_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgRsvTkGz4hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ymann/sparknotesqa.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Amn6Fz0RqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/sparknotesqa')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kS_3q136VB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r ./requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjYEBxT68Ein",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you are using Infersent embeddings (not recommended), run this cell:\n",
        "!mkdir scripts/fastText\n",
        "!curl -Lo scripts/fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "!unzip scripts/fastText/crawl-300d-2M.vec.zip -d scripts/fastText/\n",
        "!mkdir scripts/encoder\n",
        "!curl -Lo scripts/encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cwlHd8I0q3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the dataset then run the paragraph extraction:\n",
        "!gunzip data/sparknotes_dataset.json.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sv0cq-68c5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, extract the correct paragraphs. In this example, we use the question \n",
        "# concatenated with the correct answer for training and the question \n",
        "# concatenated with all answers for test\n",
        "\n",
        "# Input flag options: \n",
        "# embedding_method : tfidf, bert, infersent, sentence_bert (recommended)\n",
        "# comparison_method: no_answers, correct_answer, all_answers\n",
        "# pool_method: best_sentence (recommended), sum, average\n",
        "# context_size: any int (set to -1 for full paragraphs) (50 is recommended)\n",
        "!python scripts/paragraph_extraction.py -embedding_method sentence_bert \\\n",
        "-comparison_method correct_answer -pool_method best_sentence -context_size 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n35lutm4zl9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python scripts/paragraph_extraction.py -embedding_method sentence_bert \\\n",
        "-comparison_method all_answers -pool_method best_sentence -context_size 50 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPajQ6zFv82d",
        "colab_type": "text"
      },
      "source": [
        "### 2. Run the fine-tuning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veAW1eqZv6bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, split the data into train, val and test sets:\n",
        "!python scripts/splitdata.py \\\n",
        "-train_data data/paragraph_extracted_data/sentence_bert_correct_answer_50.csv \\\n",
        "-val_data data/paragraph_extracted_data/sentence_bert_correct_answer_50.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AToLq-ipwkrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, clone the modified Hugging Face repository\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/gauravkmr/transformers.git\n",
        "os.chdir('/content/transformers')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eczzsxZtkHF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the fine-tunning model\n",
        "!python examples/run_multiple_choice.py \\\n",
        "--model_type roberta \\\n",
        "--task_name swag \\\n",
        "--model_name_or_path roberta-base \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--do_lower_case \\\n",
        "--data_dir /content/sparknotesqa/splitdata \\\n",
        "--learning_rate 5e-5 \\\n",
        "--num_train_epochs 3 \\\n",
        "--max_seq_length 80 \\\n",
        "--output_dir models_bert/swag_base \\\n",
        "--per_gpu_eval_batch_size=16 \\\n",
        "--per_gpu_train_batch_size=16 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "--overwrite_output"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}